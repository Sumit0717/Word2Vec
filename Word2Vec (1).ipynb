{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RksketBT1nSF",
        "outputId": "8e2e5fe1-ab86-4e18-f51a-264929be712c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim tqdm scipy scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://mattmahoney.net/dc/enwik8.zip\n",
        "!unzip enwik8.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6XtW_Sr1pO2",
        "outputId": "503b5c40-08da-4e16-ae78-72489b6899e9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-12 10:57:04--  http://mattmahoney.net/dc/enwik8.zip\n",
            "Resolving mattmahoney.net (mattmahoney.net)... 20.119.76.151\n",
            "Connecting to mattmahoney.net (mattmahoney.net)|20.119.76.151|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 36445475 (35M) [application/zip]\n",
            "Saving to: ‘enwik8.zip’\n",
            "\n",
            "enwik8.zip          100%[===================>]  34.76M  9.29MB/s    in 3.7s    \n",
            "\n",
            "2026-01-12 10:57:08 (9.29 MB/s) - ‘enwik8.zip’ saved [36445475/36445475]\n",
            "\n",
            "Archive:  enwik8.zip\n",
            "  inflating: enwik8                  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"enwik8\", \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "print(\"Total characters:\", len(text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeRLkDFR2iv_",
        "outputId": "9e441072-7128-49f1-8ca1-eb27b1474357"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total characters: 99621832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = text.lower()\n",
        "tokens = text.split()\n",
        "\n",
        "print(\"Total tokens:\", len(tokens))\n",
        "print(tokens[:20])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRi3wwvU2opE",
        "outputId": "c9da5544-05e9-4c1d-8384-a393f2f554c7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total tokens: 13303079\n",
            "['<mediawiki', 'xmlns=\"http://www.mediawiki.org/xml/export-0.3/\"', 'xmlns:xsi=\"http://www.w3.org/2001/xmlschema-instance\"', 'xsi:schemalocation=\"http://www.mediawiki.org/xml/export-0.3/', 'http://www.mediawiki.org/xml/export-0.3.xsd\"', 'version=\"0.3\"', 'xml:lang=\"en\">', '<siteinfo>', '<sitename>wikipedia</sitename>', '<base>http://en.wikipedia.org/wiki/main_page</base>', '<generator>mediawiki', '1.6alpha</generator>', '<case>first-letter</case>', '<namespaces>', '<namespace', 'key=\"-2\">media</namespace>', '<namespace', 'key=\"-1\">special</namespace>', '<namespace', 'key=\"0\"']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "VOCAB_SIZE = 30000\n",
        "\n",
        "word_counts = Counter(tokens)\n",
        "most_common = word_counts.most_common(VOCAB_SIZE)\n",
        "\n",
        "word2id = {word: i for i, (word, _) in enumerate(most_common)}\n",
        "id2word = {i: word for word, i in word2id.items()}\n",
        "\n",
        "filtered_tokens = [word2id[w] for w in tokens if w in word2id]\n",
        "\n",
        "print(\"Vocabulary size:\", len(word2id))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWYfeaFJ2rA1",
        "outputId": "66266e70-f0e0-449f-e415-e4ca412c320c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 30000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "word_freqs = np.array([count for _, count in most_common], dtype=np.float32)\n",
        "word_freqs = word_freqs ** 0.75\n",
        "word_freqs = word_freqs / word_freqs.sum()\n"
      ],
      "metadata": {
        "id": "pb-4cUdX2teF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n"
      ],
      "metadata": {
        "id": "X8uLuvPI21O3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SkipGramNS(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim):\n",
        "        super().__init__()\n",
        "        self.input_embed = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.output_embed = nn.Embedding(vocab_size, embed_dim)\n",
        "\n",
        "    def forward(self, center, context, negatives):\n",
        "        center_vec = self.input_embed(center)\n",
        "        context_vec = self.output_embed(context)\n",
        "        neg_vec = self.output_embed(negatives)\n",
        "\n",
        "        pos_score = torch.sum(center_vec * context_vec, dim=1)\n",
        "        pos_loss = -torch.log(torch.sigmoid(pos_score))\n",
        "\n",
        "        neg_score = torch.bmm(neg_vec, center_vec.unsqueeze(2)).squeeze()\n",
        "        neg_loss = -torch.log(torch.sigmoid(-neg_score)).sum(1)\n",
        "\n",
        "        return (pos_loss + neg_loss).mean()\n"
      ],
      "metadata": {
        "id": "w6pOm9gp24AD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "EMBED_DIM = 100\n",
        "WINDOW_SIZE = 2\n",
        "NEG_SAMPLES = 5\n",
        "BATCH_SIZE = 512\n",
        "EPOCHS = 2\n",
        "\n",
        "model = SkipGramNS(len(word2id), EMBED_DIM).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.003)\n"
      ],
      "metadata": {
        "id": "cBe9Zz5R26J2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    for epoch in range(EPOCHS):\n",
        "        total_loss = 0\n",
        "\n",
        "        for i in tqdm(range(0, len(filtered_tokens), BATCH_SIZE)):\n",
        "            batch = filtered_tokens[i:i+BATCH_SIZE]\n",
        "\n",
        "            centers, contexts, negatives = [], [], []\n",
        "\n",
        "            for idx, center in enumerate(batch):\n",
        "                for j in range(max(0, idx-WINDOW_SIZE), min(len(batch), idx+WINDOW_SIZE+1)):\n",
        "                    if idx != j:\n",
        "                        centers.append(center)\n",
        "                        contexts.append(batch[j])\n",
        "                        negs = np.random.choice(len(word2id), NEG_SAMPLES, p=word_freqs)\n",
        "                        negatives.append(negs)\n",
        "\n",
        "            if not centers:\n",
        "                continue\n",
        "\n",
        "            centers = torch.tensor(centers).to(device)\n",
        "            contexts = torch.tensor(contexts).to(device)\n",
        "            negatives = torch.tensor(negatives).to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss = model(centers, contexts, negatives)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "i5pJhEc429LH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voqbwKqM3BnS",
        "outputId": "1ab27f10-0d46-41b2-cd6c-9e1e715a947f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/20733 [00:00<?, ?it/s]/tmp/ipython-input-231790674.py:23: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)\n",
            "  negatives = torch.tensor(negatives).to(device)\n",
            " 85%|████████▍ | 17603/20733 [3:26:59<35:03,  1.49it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = model.input_embed.weight.detach().cpu().numpy()\n"
      ],
      "metadata": {
        "id": "piRFc9Lr3DC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "gensim_model = KeyedVectors.load_word2vec_format(\n",
        "    \"GoogleNews-vectors-negative300.bin\",\n",
        "    binary=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "vPaFxymV3Ifm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "def cosine_sim(v1, v2):\n",
        "    return 1 - cosine(v1, v2)\n",
        "\n",
        "word = \"king\"\n",
        "\n",
        "our_vec = embeddings[word2id[word]]\n",
        "gensim_vec = gensim_model[word][:EMBED_DIM]\n",
        "\n",
        "print(\"Cosine similarity:\", cosine_sim(our_vec, gensim_vec))\n"
      ],
      "metadata": {
        "id": "errQmnQ-3KiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analogy(a, b, c, topn=5):\n",
        "    vec = embeddings[word2id[b]] - embeddings[word2id[a]] + embeddings[word2id[c]]\n",
        "\n",
        "    scores = []\n",
        "    for i in range(len(embeddings)):\n",
        "        sim = cosine_sim(vec, embeddings[i])\n",
        "        scores.append((id2word[i], sim))\n",
        "\n",
        "    return sorted(scores, key=lambda x: x[1], reverse=True)[:topn]\n"
      ],
      "metadata": {
        "id": "mlHTtnev3MuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analogy(\"man\", \"king\", \"woman\")\n"
      ],
      "metadata": {
        "id": "utigDa0W3YyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gender_direction = embeddings[word2id[\"he\"]] - embeddings[word2id[\"she\"]]\n"
      ],
      "metadata": {
        "id": "O2wXtEdW3awI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "professions = [\"doctor\", \"nurse\", \"engineer\", \"teacher\"]\n",
        "\n",
        "for p in professions:\n",
        "    score = cosine_sim(embeddings[word2id[p]], gender_direction)\n",
        "    print(p, score)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ic-_eiZe3ckJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Q6BdD293eWj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}